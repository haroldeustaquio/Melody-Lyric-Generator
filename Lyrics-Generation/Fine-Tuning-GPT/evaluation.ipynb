{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./gpt2_model_trained_1\"\n",
    "model_1 = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer_1 = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./gpt2_model_trained_2\"\n",
    "model_2 = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./gpt2_model_trained_3\"\n",
    "model_3 = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer_3 = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "En México me encuentro, el sol brilla al pasar,  \n",
      "colores en las calles, mil historias al andar.  \n",
      "Una noche tan tranquila mas hermosa voy encontrarme amor llegar tarde aquel mismo mañana temprano llegaste tierra luna contigo quiero ir pues va ser solo sueño vida pronto va tenerte asi cuerpo alma volver aunque nunca vuelva volver dar gracias ay cielo ahora adios siempre veo you might also likecuando llegue mañana vuelvo regresar vas vere camino vez ayer conocide extraño mundo junto hoy cerca lado esperando pueda ver si miras ojos luz piel niña ven vi venir lejos dejas pensar oh why digandose sera lugar esperare buscarle uoh yeaah amor llegara amanecer busque puedo hacer si si ves capaz conmigo amor ir caminando rumbo esperar sabes bien sabra quieres encontrar toda camino siento cada detalle forma diferente da cuenta tiempo igual pasado soledad ah hara dios ay noche tanta gente feliz vivir juntos hace falta calor agua aguanto naci buscando lluvia mar estrellas salen flores rosa rosas dulce besos hacen caso daria momento juro caminar mano salgas corazon llego brazos luego mas hermoso sueño pasa casa pontes puerta boca manos mientras lloro dentro sigue triste tristeza sienta pies dia llorando despierta amor oye palabras rompes miedo hacias tantas veces amando verdad dice ¿como queria si hablas sido tantos años quedamos dos padres padre mio hijo mio niño mio mio hijo mio hijo mio padre mio niño mio mio amigo mio hijo mio mio padre mio\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "En México me encuentro, el sol brilla al pasar,  \n",
    "colores en las calles, mil historias al andar.  \n",
    "\"\"\"\n",
    "\n",
    "input_ids_1 = tokenizer_1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "output = model_1.generate(\n",
    "    input_ids=input_ids_1,\n",
    "    max_length=300,\n",
    "    min_length=200,\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.8,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer_1.eos_token_id,\n",
    ")\n",
    "\n",
    "generated_text_1 = tokenizer_1.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "En México me encuentro, el sol brilla al pasar,  \n",
      "colores en las calles, mil historias al andar.  \n",
      "lores siempre va igual vida entera vanidad tiempo mas dias voy conocerme si miro hacer preguntas ¿que puedo hacer cosas tan solo dos amigos saben hablar nunca habra sido parte de nadie vivo ahora sabe sentirte bien siento asi estare esperando vine aqui amor sabes decir mentiras oh digo verdad piensas quiero mas ser feliz vivir aunque tener tantas ganas quererlo puedes creer veces conmigo quise ir lejos you might also likeyo ahora seguro saberes amo amo ahora mismo sabras quiero aunque dices duele mundo contigo extraño importa lado vuelvas lado cada vez sigo haciendo aquello debia ser libre aceptar perdonar corazon sera culpable gente vengo pensar dejare olvidar razon alguien cree culpa da pena vale sufrir hace falta pa perder dinero culpa vale sufrir hecho mejor vale tener valor mejor vale tener merezco oir pagar woh ow okay ozuy osamo otobo ire soñarte primera vez mas ves mal dire cariño dar trato dudo hablarnos vamos cantar hablandomos jamas veremos bailar senti felices llorar lloramos vivimos juntos cantamos guitarra querernos escuchar canciones amando yeatulambamos hacemos fiesta little eyes ire soplice todas partes hey hoy imaginas realidad noche fingir das cuenta perdi amar creo arrepiento menos pense buscar\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "En México me encuentro, el sol brilla al pasar,  \n",
    "colores en las calles, mil historias al andar.  \n",
    "\"\"\"\n",
    "\n",
    "input_ids_2 = tokenizer_2(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "output = model_2.generate(\n",
    "    input_ids=input_ids_2,\n",
    "    max_length=300,\n",
    "    min_length=200,\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.8,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer_2.eos_token_id,\n",
    ")\n",
    "\n",
    "generated_text_2 = tokenizer_2.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "En México me encuentro, el sol brilla al pasar,  \n",
      "colores en las calles, mil historias al andar.  \n",
      " Suspirar conmigo camino caminar siempre lado ciudad voy contando vida mia quiero darte mano dio mano quiero darme beso siempre quiero darle beso nunca imagine quisiera tener vayas solo amor dijiste si lado aqui junto quiero darlo beso siempre quiero darles beso besos si dos dias enamorado mujer see luis miguel liveget tickets as low as you might also like\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "En México me encuentro, el sol brilla al pasar,  \n",
    "colores en las calles, mil historias al andar.  \n",
    "\"\"\"\n",
    "\n",
    "input_ids_3 = tokenizer_3(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "output = model_3.generate(\n",
    "    input_ids=input_ids_3,\n",
    "    max_length=300,\n",
    "    min_length=200,\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.8,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer_3.eos_token_id,\n",
    ")\n",
    "\n",
    "generated_text_3 = tokenizer_3.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, input_ids):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        perplexity = torch.exp(loss)\n",
    "    return perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_n(text, n):\n",
    "    tokens = text.split()\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    unique_ngrams = set(ngrams)\n",
    "    return len(unique_ngrams) / len(tokens) if tokens else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    unique_tokens = set(tokens)\n",
    "    return len(unique_tokens) / len(tokens) if tokens else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def local_coherence(text):\n",
    "    sentences = text.split('.')\n",
    "    coherence_scores = []\n",
    "    for i in range(len(sentences) - 1):\n",
    "        emb1 = embedding_model.encode(sentences[i], convert_to_tensor=True)\n",
    "        emb2 = embedding_model.encode(sentences[i + 1], convert_to_tensor=True)\n",
    "        similarity = util.cos_sim(emb1, emb2).item()\n",
    "        coherence_scores.append(similarity)\n",
    "    return sum(coherence_scores) / len(coherence_scores) if coherence_scores else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_text(model, input_ids, text):\n",
    "    return {\n",
    "        \"Perplexity\": calculate_perplexity(model, input_ids),\n",
    "        \"Distinct-1\": distinct_n(text, 1),\n",
    "        \"Distinct-2\": distinct_n(text, 2),\n",
    "        \"Lexical Diversity\": lexical_diversity(text),\n",
    "        \"Local Coherence\": local_coherence(text),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_1 = evaluate_text(model_1, input_ids_1,generated_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_2 = evaluate_text(model_2, input_ids_2,generated_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_3 = evaluate_text(model_3, input_ids_3,generated_text_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Perplexity': 354.3334045410156,\n",
       " 'Distinct-1': 0.8600823045267489,\n",
       " 'Distinct-2': 0.9423868312757202,\n",
       " 'Lexical Diversity': 0.854251012145749,\n",
       " 'Local Coherence': 0.3659774661064148}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Perplexity': 611.615234375,\n",
       " 'Distinct-1': 0.9018691588785047,\n",
       " 'Distinct-2': 0.9813084112149533,\n",
       " 'Lexical Diversity': 0.8944954128440367,\n",
       " 'Local Coherence': 0.4278242290019989}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Perplexity': 456.8043518066406,\n",
       " 'Distinct-1': 0.8181818181818182,\n",
       " 'Distinct-2': 0.961038961038961,\n",
       " 'Lexical Diversity': 0.8024691358024691,\n",
       " 'Local Coherence': 0.4308878183364868}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
