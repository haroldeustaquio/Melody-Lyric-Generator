{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Melody-Lyric-Generator\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./gpt2_model_trained_1\"\n",
    "model_1 = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer_1 = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./gpt2_model_trained_2\"\n",
    "model_2 = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./gpt2_model_trained_3\"\n",
    "model_3 = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer_3 = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./gpt2_model_trained_4\"\n",
    "model_4 = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer_4 = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "En México me encuentro, el sol brilla al pasar,  \n",
      "colores en las calles, mil historias al andar.  \n",
      " quiero verlas piensas siento mas tan solo amor cada noche voy caminar juntos lado siempre feliz ven aqui va hacerme sentir hoy vuelto puedo decirlo mireste amo vas marchar cielo nunca pierdes vida entera amar contigo vuelvas ser mejor ahora sientes ganas volver vez si miras jamas sabras dios vuelves querer verte llorare amar vivo tiempo esperar pues mia necesito cariño daria quererte olvidarnos ayer bien pronto regreses mañana estaras esperando lejos vivir aunque llegue tarde conocimos dos años querido regresarte luna primavera calor verano besos sueños tristes ilusiones traigo pensamiento extraño pensar oir miedo ir cambiando you might also like\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "En México me encuentro, el sol brilla al pasar,  \n",
    "colores en las calles, mil historias al andar.  \n",
    "\"\"\"\n",
    "\n",
    "input_ids_1 = tokenizer_1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "output = model_1.generate(\n",
    "    input_ids=input_ids_1,\n",
    "    max_length=300,\n",
    "    min_length=200,\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.8,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer_1.eos_token_id,\n",
    ")\n",
    "\n",
    "generated_text_1 = tokenizer_1.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " quiero verlas piensas siento mas tan solo amor cada noche voy caminar juntos lado siempre feliz ven aqui va hacerme sentir hoy vuelto puedo decirlo mireste amo vas marchar cielo nunca pierdes vida entera amar contigo vuelvas ser mejor ahora sientes ganas volver vez si miras jamas sabras dios vuelves querer verte llorare amar vivo tiempo esperar pues mia necesito cariño daria quererte olvidarnos ayer bien pronto regreses mañana estaras esperando lejos vivir aunque llegue tarde conocimos dos años querido regresarte luna primavera calor verano besos sueños tristes ilusiones traigo pensamiento extraño pensar oir miedo ir cambiando you might also like\n"
     ]
    }
   ],
   "source": [
    "generated_text_without_prompt_1 = tokenizer_1.decode(\n",
    "    output[0][input_ids_1.shape[1]:],  # Quitar las tokens del prompt\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "print(generated_text_without_prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "En México me encuentro, el sol brilla al pasar,  \n",
      "colores en las calles, mil historias al andar.  \n",
      "lores hablas amor vida nunca muere solo corazon vive mejor aqui mas profundo alma amor importa si mas tiempo pasa ayer oh yeak besos negros sueños color verde gris azul rosas van muriendo buscando mirada cada beso siento soledad puedo hacer conmigo olvidarte quiero you might also like\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "En México me encuentro, el sol brilla al pasar,  \n",
    "colores en las calles, mil historias al andar.  \n",
    "\"\"\"\n",
    "\n",
    "input_ids_2 = tokenizer_2(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "output = model_2.generate(\n",
    "    input_ids=input_ids_2,\n",
    "    max_length=300,\n",
    "    min_length=200,\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.8,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer_2.eos_token_id,\n",
    ")\n",
    "\n",
    "generated_text_2 = tokenizer_2.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lores hablas amor vida nunca muere solo corazon vive mejor aqui mas profundo alma amor importa si mas tiempo pasa ayer oh yeak besos negros sueños color verde gris azul rosas van muriendo buscando mirada cada beso siento soledad puedo hacer conmigo olvidarte quiero you might also like\n"
     ]
    }
   ],
   "source": [
    "generated_text_without_prompt_2 = tokenizer_2.decode(\n",
    "    output[0][input_ids_2.shape[1]:],  # Quitar las tokens del prompt\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "print(generated_text_without_prompt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "En México me encuentro, el sol brilla al pasar,  \n",
      "colores en las calles, mil historias al andar.  \n",
      "- Dejo hablaran contigo hoy quiero verlos aunque nunca olvidas veces olvides ayer favor adios see luis miguel liveget tickets as low as you might also likeyo amandote tan sensual asi besarte cuerpo quiero conocerme sentirlo abrazame si busque mujer puedo entender corazon dejes ir pronto todavia quiera volver conmigo quiero saber besos beso muero vez mas amor tendre lugar cerca veo siento dentro siempre presente mientras viva voz mundo entero cambio solo silencio puedes evitar realidad pienses bien creo nadie sabre voy decir momento vas olvidar hablemos momentos diran siquiera sera seguro verdad hiciste daño quererte cada instante tambien vuelvo loco hoy fingir encuentres nuevo nombre aqui mañana mas grande ¿por ahora puedo vivir aun ser feliz ahora quieres saber baby si busques desnuda quiero conocer vida entera quiero saber cuanto mejor hacer ¿como digas sufrir perdis pasearia pasare ganas tener sueños dia noche lado estara junto\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "En México me encuentro, el sol brilla al pasar,  \n",
    "colores en las calles, mil historias al andar.  \n",
    "\"\"\"\n",
    "\n",
    "input_ids_3 = tokenizer_3(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "output = model_3.generate(\n",
    "    input_ids=input_ids_3,\n",
    "    max_length=300,\n",
    "    min_length=200,\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.8,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer_3.eos_token_id,\n",
    ")\n",
    "\n",
    "generated_text_3 = tokenizer_3.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dejo hablaran contigo hoy quiero verlos aunque nunca olvidas veces olvides ayer favor adios see luis miguel liveget tickets as low as you might also likeyo amandote tan sensual asi besarte cuerpo quiero conocerme sentirlo abrazame si busque mujer puedo entender corazon dejes ir pronto todavia quiera volver conmigo quiero saber besos beso muero vez mas amor tendre lugar cerca veo siento dentro siempre presente mientras viva voz mundo entero cambio solo silencio puedes evitar realidad pienses bien creo nadie sabre voy decir momento vas olvidar hablemos momentos diran siquiera sera seguro verdad hiciste daño quererte cada instante tambien vuelvo loco hoy fingir encuentres nuevo nombre aqui mañana mas grande ¿por ahora puedo vivir aun ser feliz ahora quieres saber baby si busques desnuda quiero conocer vida entera quiero saber cuanto mejor hacer ¿como digas sufrir perdis pasearia pasare ganas tener sueños dia noche lado estara junto\n"
     ]
    }
   ],
   "source": [
    "generated_text_without_prompt_3 = tokenizer_3.decode(\n",
    "    output[0][input_ids_3.shape[1]:],  # Quitar las tokens del prompt\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "print(generated_text_without_prompt_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "En México me encuentro, el sol brilla al pasar,  \n",
      "colores en las calles, mil historias al andar.  \n",
      "En Ciudad de los sueños conmigo entiendes tan solo espero cada beso contigo amor dos caras siempre lado asi seras amigo mas querido aqui mundo extraño ahora vengo encontrar manera salir diferente sabes verdad quiero sentir cuerpo mia forma mirarme ojos darte cuenta necesito vivir dentro nuevo mejor si quieres ver luz dimelo tenerlo decir alguien escuchara hablas tantas cosas contarnos momentos daran alguna vez jamas habra historia tiempo vivido vida entera see julieta venegas liveget tickets as low as you might also like\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "En México me encuentro, el sol brilla al pasar,  \n",
    "colores en las calles, mil historias al andar.  \n",
    "\"\"\"\n",
    "\n",
    "input_ids_4 = tokenizer_4(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "output = model_4.generate(\n",
    "    input_ids=input_ids_4,\n",
    "    max_length=300,\n",
    "    min_length=200,\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.8,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer_4.eos_token_id,\n",
    ")\n",
    "\n",
    "generated_text_4 = tokenizer_4.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En Ciudad de los sueños conmigo entiendes tan solo espero cada beso contigo amor dos caras siempre lado asi seras amigo mas querido aqui mundo extraño ahora vengo encontrar manera salir diferente sabes verdad quiero sentir cuerpo mia forma mirarme ojos darte cuenta necesito vivir dentro nuevo mejor si quieres ver luz dimelo tenerlo decir alguien escuchara hablas tantas cosas contarnos momentos daran alguna vez jamas habra historia tiempo vivido vida entera see julieta venegas liveget tickets as low as you might also like\n"
     ]
    }
   ],
   "source": [
    "generated_text_without_prompt_4 = tokenizer_4.decode(\n",
    "    output[0][input_ids_4.shape[1]:],  # Quitar las tokens del prompt\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "print(generated_text_without_prompt_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, tokenizer, text_total):\n",
    "    input_ids = tokenizer(text_total, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        perplexity = torch.exp(loss)\n",
    "    \n",
    "    return perplexity.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_n(text, n):\n",
    "    tokens = text.split()\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    unique_ngrams = set(ngrams)\n",
    "    return len(unique_ngrams) / len(tokens) if tokens else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    unique_tokens = set(tokens)\n",
    "    return len(unique_tokens) / len(tokens) if tokens else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def local_coherence(text):\n",
    "    sentences = text.split('.')\n",
    "    coherence_scores = []\n",
    "    for i in range(len(sentences) - 1):\n",
    "        emb1 = embedding_model.encode(sentences[i], convert_to_tensor=True)\n",
    "        emb2 = embedding_model.encode(sentences[i + 1], convert_to_tensor=True)\n",
    "        similarity = util.cos_sim(emb1, emb2).item()\n",
    "        coherence_scores.append(similarity)\n",
    "    return sum(coherence_scores) / len(coherence_scores) if coherence_scores else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_text(model, tokenizer, text_total, text_generated):\n",
    "    return {\n",
    "        \"Perplexity\": calculate_perplexity(model,tokenizer, text_total),\n",
    "        \"Distinct-2\": distinct_n(text_generated, 2),\n",
    "        \"Lexical Diversity\": lexical_diversity(text_generated),\n",
    "        \"Local Coherence\": local_coherence(text_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Perplexity': 71.47877502441406,\n",
       " 'Distinct-2': 0.9900990099009901,\n",
       " 'Lexical Diversity': 0.9900990099009901,\n",
       " 'Local Coherence': 0.3658442199230194}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_1 = evaluate_text(model_1, tokenizer_1, generated_text_1, generated_text_without_prompt_1)\n",
    "metrics_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Perplexity': 87.86155700683594,\n",
       " 'Distinct-2': 0.9791666666666666,\n",
       " 'Lexical Diversity': 0.9583333333333334,\n",
       " 'Local Coherence': 0.4929533004760742}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_2 = evaluate_text(model_2, tokenizer_2, generated_text_2, generated_text_without_prompt_2)\n",
    "metrics_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Perplexity': 42.923221588134766,\n",
       " 'Distinct-2': 0.9864864864864865,\n",
       " 'Lexical Diversity': 0.918918918918919,\n",
       " 'Local Coherence': 0.3888491690158844}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_3 = evaluate_text(model_3, tokenizer_3, generated_text_3, generated_text_without_prompt_3)\n",
    "metrics_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Perplexity': 36.7916145324707,\n",
       " 'Distinct-2': 0.9880952380952381,\n",
       " 'Lexical Diversity': 0.9880952380952381,\n",
       " 'Local Coherence': 0.44628340005874634}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_4 = evaluate_text(model_4, tokenizer_4, generated_text_4, generated_text_without_prompt_4)\n",
    "metrics_4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
